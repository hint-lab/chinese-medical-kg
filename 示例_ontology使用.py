#!/usr/bin/env python3
"""
ä¸­æ–‡åŒ»å­¦æœ¬ä½“ä½¿ç”¨ç¤ºä¾‹
ç®€å•ã€ç›´è§‚çš„æ¼”ç¤ºä»£ç 
"""

from ontology.ontology_loader import OntologyLoader
from ontology.entity_linker import EntityLinker


def print_section(title):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def demo_basic_usage():
    """æ¼”ç¤ºåŸºç¡€ç”¨æ³•"""
    print_section("1. åŠ è½½æœ¬ä½“æ•°æ®")
    
    loader = OntologyLoader()
    print(f"âœ… å·²åŠ è½½è¯ç‰©: {len(loader.drugs):,} æ¡")
    print(f"âœ… å·²åŠ è½½ç–¾ç—…: {len(loader.diseases):,} æ¡")
    print(f"âœ… å·²åŠ è½½åŸºå› : {len(loader.genes):,} æ¡")
    
    return loader


def demo_exact_match(linker):
    """æ¼”ç¤ºç²¾ç¡®åŒ¹é…"""
    print_section("2. ç²¾ç¡®åŒ¹é…")
    
    test_drugs = ["é˜¿å¸åŒ¹æ—", "äºŒç”²åŒèƒ", "å¸•åšåˆ©ç å•æŠ—"]
    
    for drug_name in test_drugs:
        result = linker.link(drug_name)
        if result:
            print(f"âœ… '{drug_name}'")
            print(f"   æ ‡å‡†å: {result['standard_name']}")
            print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            print(f"   åŒ¹é…ç±»å‹: {result['match_type']}")
        else:
            print(f"âŒ '{drug_name}' - æœªæ‰¾åˆ°")


def demo_alias_match(linker):
    """æ¼”ç¤ºåˆ«ååŒ¹é…"""
    print_section("3. åˆ«åè¯†åˆ«")
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…å­˜åœ¨çš„åˆ«åæ•°æ®
    test_cases = [
        ("å¸•åšåˆ©ç å•æŠ—", "æ ‡å‡†å"),
        ("å¯ç‘è¾¾", "å¦‚æœæœ‰åˆ«åæ•°æ®ä¼šåŒ¹é…"),
    ]
    
    for drug_name, note in test_cases:
        result = linker.link(drug_name)
        if result:
            print(f"âœ… '{drug_name}' ({note})")
            print(f"   â†’ æ ‡å‡†å: {result['standard_name']}")
            print(f"   â†’ ç½®ä¿¡åº¦: {result['confidence']:.2f}")
        else:
            print(f"â„¹ï¸  '{drug_name}' - {note}")


def demo_fuzzy_match(linker):
    """æ¼”ç¤ºæ¨¡ç³ŠåŒ¹é…"""
    print_section("4. æ¨¡ç³ŠåŒ¹é…ï¼ˆå®¹é”™ï¼‰")
    
    # æ‹¼å†™é”™è¯¯çš„ä¾‹å­
    test_cases = [
        ("é˜¿æ–¯åŒ¹æ—", 85),    # é”™è¯¯æ‹¼å†™
        ("äºŒç”²åŒç“œ", 80),    # é”™è¯¯æ‹¼å†™
        ("å¸•åšåˆ©å•æŠ—", 85),  # å°‘ä¸€ä¸ªå­—
    ]
    
    for drug_name, threshold in test_cases:
        result = linker.link(drug_name, threshold=threshold)
        if result:
            print(f"âœ… '{drug_name}' (é˜ˆå€¼: {threshold})")
            print(f"   â†’ åŒ¹é…åˆ°: {result['standard_name']}")
            print(f"   â†’ ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            print(f"   â†’ ç±»å‹: {result['match_type']}")
        else:
            print(f"âŒ '{drug_name}' - æœªåŒ¹é…ï¼ˆé˜ˆå€¼: {threshold}ï¼‰")


def demo_batch_processing(linker):
    """æ¼”ç¤ºæ‰¹é‡å¤„ç†"""
    print_section("5. æ‰¹é‡å¤„ç†")
    
    drug_list = [
        "é˜¿å¸åŒ¹æ—",
        "äºŒç”²åŒèƒ",
        "èƒ°å²›ç´ ",
        "æœªçŸ¥è¯ç‰©",
        "å¸•åšåˆ©ç å•æŠ—",
    ]
    
    print(f"æ‰¹é‡å¤„ç† {len(drug_list)} ä¸ªè¯ç‰©åç§°...")
    results = linker.link_batch(drug_list)
    
    matched = 0
    for drug_name, result in zip(drug_list, results):
        if result:
            matched += 1
            print(f"âœ… {drug_name:12} â†’ {result['standard_name']}")
        else:
            print(f"âŒ {drug_name:12} â†’ æœªåŒ¹é…")
    
    print(f"\nåŒ¹é…ç‡: {matched}/{len(drug_list)} ({matched/len(drug_list)*100:.1f}%)")


def demo_statistics(linker):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print_section("6. ç»Ÿè®¡ä¿¡æ¯")
    
    stats = linker.get_statistics()
    print(f"å®ä½“æ€»æ•°: {stats['total_entities']:,}")
    print(f"åˆ«åæ€»æ•°: {stats['total_aliases']:,}")
    print(f"ç´¢å¼•é”®æ€»æ•°: {stats['total_keys']:,}")


def demo_real_world_example(drug_linker, disease_linker):
    """å®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º"""
    print_section("7. å®é™…åº”ç”¨ï¼šåŒ»ç–—æ–‡æœ¬æ ‡å‡†åŒ–")
    
    # æ¨¡æ‹Ÿä»åŒ»ç–—æ–‡æœ¬ä¸­æå–çš„å®ä½“
    extracted_entities = {
        "drugs": ["é˜¿å¸åŒ¹æ—", "äºŒç”²åŒèƒ"],
        "diseases": ["ç³–å°¿ç—…", "é«˜è¡€å‹", "å† å¿ƒç—…"]
    }
    
    print("åŸå§‹æ–‡æœ¬æå–ç»“æœ:")
    print(f"  è¯ç‰©: {', '.join(extracted_entities['drugs'])}")
    print(f"  ç–¾ç—…: {', '.join(extracted_entities['diseases'])}")
    
    print("\næ ‡å‡†åŒ–å:")
    
    # æ ‡å‡†åŒ–è¯ç‰©
    standardized_drugs = []
    for drug in extracted_entities['drugs']:
        result = drug_linker.link(drug)
        if result:
            standardized_drugs.append(result['standard_name'])
    print(f"  è¯ç‰©: {', '.join(standardized_drugs)}")
    
    # æ ‡å‡†åŒ–ç–¾ç—…
    standardized_diseases = []
    for disease in extracted_entities['diseases']:
        result = disease_linker.link(disease)
        if result:
            standardized_diseases.append(result['standard_name'])
        else:
            standardized_diseases.append(f"{disease}(æœªåŒ¹é…)")
    print(f"  ç–¾ç—…: {', '.join(standardized_diseases)}")


def demo_quality_check(linker):
    """æ¼”ç¤ºæ•°æ®è´¨é‡æ£€æŸ¥"""
    print_section("8. æ•°æ®è´¨é‡æ£€æŸ¥")
    
    # æ¨¡æ‹Ÿæ•°æ®åº“ä¸­çš„è¯ç‰©åç§°ï¼ˆæœ‰æ ‡å‡†çš„ä¹Ÿæœ‰éæ ‡å‡†çš„ï¼‰
    database_drugs = [
        "é˜¿å¸åŒ¹æ—",      # æ ‡å‡†
        "é˜¿æ–¯åŒ¹æ—",      # æ‹¼å†™é”™è¯¯
        "ä¸å­˜åœ¨çš„è¯ç‰©",   # ä¸å­˜åœ¨
        "äºŒç”²åŒèƒ",      # æ ‡å‡†
    ]
    
    print("æ£€æŸ¥æ•°æ®åº“ä¸­çš„è¯ç‰©åç§°è§„èŒƒæ€§ï¼š")
    
    issues = 0
    for drug_name in database_drugs:
        result = linker.link(drug_name)
        
        if result is None:
            print(f"âŒ '{drug_name}' - ä¸åœ¨æ ‡å‡†æœ¬ä½“ä¸­ï¼Œéœ€è¦äººå·¥å®¡æ ¸")
            issues += 1
        elif result['match_type'] == 'fuzzy':
            print(f"âš ï¸  '{drug_name}' - å»ºè®®æ”¹ä¸º '{result['standard_name']}'")
            issues += 1
        else:
            print(f"âœ… '{drug_name}' - å·²æ ‡å‡†åŒ–")
    
    print(f"\nè´¨é‡è¯„ä¼°: å‘ç° {issues} ä¸ªé—®é¢˜")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸš€" * 30)
    print("      ä¸­æ–‡åŒ»å­¦æœ¬ä½“ï¼ˆOntologyï¼‰ä½¿ç”¨æ¼”ç¤º")
    print("ğŸš€" * 30)
    
    # 1. åŠ è½½æ•°æ®
    loader = demo_basic_usage()
    
    # åˆ›å»ºé“¾æ¥å™¨
    drug_linker = EntityLinker(loader.drugs)
    disease_linker = EntityLinker(loader.diseases)
    
    # 2-6. å„ç§åŒ¹é…æ¼”ç¤º
    demo_exact_match(drug_linker)
    demo_alias_match(drug_linker)
    demo_fuzzy_match(drug_linker)
    demo_batch_processing(drug_linker)
    demo_statistics(drug_linker)
    
    # 7-8. å®é™…åº”ç”¨åœºæ™¯
    demo_real_world_example(drug_linker, disease_linker)
    demo_quality_check(drug_linker)
    
    print("\n" + "=" * 60)
    print("  æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: å¿«é€Ÿä½¿ç”¨æŒ‡å—.md")
    print("  - æŸ¥çœ‹æœ¬ä½“æ•°æ®: ontology/data/")
    print("  - è¿è¡Œæµ‹è¯•: pytest tests/")
    print("\n")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("\nå¯èƒ½çš„åŸå› :")
        print("  1. æœªå®‰è£…ä¾èµ–: pip install -r requirements.txt")
        print("  2. æœ¬ä½“æ•°æ®æœªæ„å»º: python scripts/build_ontology.py")
        print("  3. ç¼ºå°‘å¿…è¦çš„å·¥å…·æ¨¡å—")
        import traceback
        traceback.print_exc()

