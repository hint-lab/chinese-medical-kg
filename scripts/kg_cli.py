#!/usr/bin/env python3
"""
ä¸­æ–‡åŒ»å­¦çŸ¥è¯†å›¾è°± - å‘½ä»¤è¡Œå·¥å…· (CLI)
"""

import argparse
import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from ontology.db_loader import MedicalKnowledgeGraphDB


def search_entity(db, name, entity_type=None, output_format='text'):
    """æœç´¢å®ä½“"""
    result = db.search_entity(name, entity_type)
    
    if not result:
        print(f"âŒ æœªæ‰¾åˆ°: {name}", file=sys.stderr)
        return None
    
    if output_format == 'json':
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print(f"âœ… æ‰¾åˆ°: {result['name']} ({result['type']})")
        print(f"   æ ‡å‡†åç§°: {result['standard_name']}")
        print(f"   æ•°æ®æ¥æº: {result['source']}")
        
        aliases = db.get_aliases(result['name'])
        if aliases and aliases != ['nan']:
            # è¿‡æ»¤æ‰nanå€¼
            aliases = [a for a in aliases if a and str(a).lower() != 'nan']
            if aliases:
                print(f"   åˆ«å: {', '.join(aliases[:5])}")
                if len(aliases) > 5:
                    print(f"         ... è¿˜æœ‰ {len(aliases) - 5} ä¸ª")
    
    return result


def fuzzy_search(db, keyword, entity_type=None, limit=10, output_format='text'):
    """æ¨¡ç³Šæœç´¢"""
    results = db.fuzzy_search(keyword, entity_type, limit)
    
    if not results:
        print(f"âŒ æœªæ‰¾åˆ°åŒ…å« '{keyword}' çš„å®ä½“", file=sys.stderr)
        return []
    
    if output_format == 'json':
        print(json.dumps(results, ensure_ascii=False, indent=2))
    else:
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
        for i, r in enumerate(results, 1):
            print(f"  {i}. {r['name']} ({r['type']})")
    
    return results


def get_drug_targets(db, drug_name, output_format='text'):
    """æŸ¥è¯¢è¯ç‰©çš„é¶ç‚¹"""
    targets = db.get_drug_targets(drug_name)
    
    if not targets:
        print(f"âŒ æœªæ‰¾åˆ° '{drug_name}' çš„é¶ç‚¹ä¿¡æ¯", file=sys.stderr)
        return []
    
    if output_format == 'json':
        print(json.dumps(targets, ensure_ascii=False, indent=2))
    else:
        print(f"âœ… {drug_name} çš„é¶ç‚¹ ({len(targets)} ä¸ª):")
        for i, t in enumerate(targets, 1):
            print(f"  {i}. {t['target_name']}")
            for key in ['mode_of_action', 'highest_status']:
                if key in t:
                    print(f"     {key}: {t[key]}")
    
    return targets


def get_target_drugs(db, target_name, output_format='text'):
    """æŸ¥è¯¢é¶ç‚¹çš„è¯ç‰©"""
    drugs = db.get_target_drugs(target_name)
    
    if not drugs:
        print(f"âŒ æœªæ‰¾åˆ°é’ˆå¯¹ '{target_name}' çš„è¯ç‰©", file=sys.stderr)
        return []
    
    if output_format == 'json':
        print(json.dumps(drugs, ensure_ascii=False, indent=2))
    else:
        print(f"âœ… é’ˆå¯¹ {target_name} çš„è¯ç‰© ({len(drugs)} ä¸ª):")
        for i, d in enumerate(drugs, 1):
            print(f"  {i}. {d['drug_name']}")
            for key in ['mode_of_action', 'highest_status']:
                if key in d:
                    print(f"     {key}: {d[key]}")
    
    return drugs


def show_statistics(db, output_format='text'):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    stats = db.get_statistics()
    
    if output_format == 'json':
        print(json.dumps(stats, ensure_ascii=False, indent=2))
    else:
        print("=" * 70)
        print("  çŸ¥è¯†å›¾è°±ç»Ÿè®¡")
        print("=" * 70)
        print(f"\nå®ä½“æ€»æ•°: {stats.get('total_entities', 0):,}")
        print(f"  ğŸ’Š è¯ç‰©:     {stats.get('drugs', 0):,}")
        print(f"  ğŸ¥ ç–¾ç—…:     {stats.get('diseases', 0):,}")
        print(f"  ğŸ§¬ åŸºå› /é¶ç‚¹: {stats.get('genes', 0):,}")
        print(f"\nå…³ç³»æ€»æ•°: {stats.get('total_relations', 0):,}")
        print(f"åˆ«åæ€»æ•°: {stats.get('total_aliases', 0):,}")
        print(f"\næ•°æ®æ¥æº: {stats.get('data_sources', 'Unknown')}")
        print(f"ç‰ˆæœ¬: {stats.get('version', 'Unknown')}")
    
    return stats


def main():
    parser = argparse.ArgumentParser(
        description='ä¸­æ–‡åŒ»å­¦çŸ¥è¯†å›¾è°±å‘½ä»¤è¡Œå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æœç´¢è¯ç‰©
  %(prog)s search é˜¿å¸åŒ¹æ— --type Drug
  
  # æ¨¡ç³Šæœç´¢
  %(prog)s fuzzy ç³–å°¿ --limit 5
  
  # æŸ¥è¯¢è¯ç‰©çš„é¶ç‚¹
  %(prog)s drug-targets Ibrance
  
  # æŸ¥è¯¢é¶ç‚¹çš„è¯ç‰©
  %(prog)s target-drugs CDK4
  
  # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
  %(prog)s stats
  
  # JSONæ ¼å¼è¾“å‡º
  %(prog)s search é˜¿å¸åŒ¹æ— --json
        """
    )
    
    parser.add_argument(
        '--db',
        default=None,
        help='æ•°æ®åº“è·¯å¾„ (é»˜è®¤: é¡¹ç›®ç›®å½•ä¸‹çš„ ontology/data/medical_kg.db)'
    )
    
    parser.add_argument(
        '--json',
        action='store_true',
        help='ä»¥JSONæ ¼å¼è¾“å‡º'
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # search å‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æœç´¢å®ä½“')
    search_parser.add_argument('name', help='å®ä½“åç§°')
    search_parser.add_argument('--type', choices=['Drug', 'Disease', 'Gene'], 
                              help='å®ä½“ç±»å‹')
    
    # fuzzy å‘½ä»¤
    fuzzy_parser = subparsers.add_parser('fuzzy', help='æ¨¡ç³Šæœç´¢')
    fuzzy_parser.add_argument('keyword', help='æœç´¢å…³é”®è¯')
    fuzzy_parser.add_argument('--type', choices=['Drug', 'Disease', 'Gene'],
                             help='å®ä½“ç±»å‹')
    fuzzy_parser.add_argument('--limit', type=int, default=10,
                             help='è¿”å›ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 10)')
    
    # drug-targets å‘½ä»¤
    drug_targets_parser = subparsers.add_parser('drug-targets', 
                                                help='æŸ¥è¯¢è¯ç‰©çš„é¶ç‚¹')
    drug_targets_parser.add_argument('drug_name', help='è¯ç‰©åç§°')
    
    # target-drugs å‘½ä»¤
    target_drugs_parser = subparsers.add_parser('target-drugs',
                                                help='æŸ¥è¯¢é¶ç‚¹çš„è¯ç‰©')
    target_drugs_parser.add_argument('target_name', help='é¶ç‚¹åç§°')
    
    # stats å‘½ä»¤
    subparsers.add_parser('stats', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # åˆå§‹åŒ–æ•°æ®åº“
    try:
        if args.db is None:
            # ä½¿ç”¨é»˜è®¤è·¯å¾„
            db_path = project_root / 'ontology' / 'data' / 'medical_kg.db'
        else:
            db_path = Path(args.db)
        
        db = MedicalKnowledgeGraphDB(str(db_path))
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        print("\nè¯·å…ˆè¿è¡Œ: python scripts/migrate_to_sqlite.py", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)
    
    output_format = 'json' if args.json else 'text'
    
    try:
        # æ‰§è¡Œå‘½ä»¤
        if args.command == 'search':
            search_entity(db, args.name, args.type, output_format)
        
        elif args.command == 'fuzzy':
            fuzzy_search(db, args.keyword, args.type, args.limit, output_format)
        
        elif args.command == 'drug-targets':
            get_drug_targets(db, args.drug_name, output_format)
        
        elif args.command == 'target-drugs':
            get_target_drugs(db, args.target_name, output_format)
        
        elif args.command == 'stats':
            show_statistics(db, output_format)
    
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        db.close()


if __name__ == '__main__':
    main()

